{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"mount_file_id":"153BNkH5ThFsQPb-bcyKZiPgXhHiusAKs","authorship_tag":"ABX9TyOC3oSgI0p4+A6kpu+O76Xo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"GG0nf-PQkRe0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Bojective: Forest vs Building Classification using ANN\n","Steps:\n","Steps:\n","1. Importing (or installing) Tenosrflow, Keras and other packages on your system\n","2. Loading your data from disk\n","3. Creating your training and testing splits\n","4. Data Preprocessing\n","5. Defining your tensorflow ANN model architecture\n","6. Compiling your tensorflow ANN model\n","7. Training your model on your training data\n","8. Evaluating your model on your test data\n","9. Generate Plots for accuracy and validation loss\n","10. Saving The train model\n","11. Making predictions using your trained tensorflow model\n"],"metadata":{"id":"Iwyu05IvgxeK"}},{"cell_type":"markdown","source":["## Step 1 : Importing all the packages"],"metadata":{"id":"ed4LTgICjPlE"}},{"cell_type":"code","source":["# Import libraries and packages\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix , accuracy_score, classification_report\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.optimizers import SGD\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","import pickle\n","import cv2\n","import os\n","#time.time(); print('Time taken: (:.1f) seconds'.format(time.time() - timel))\n","import time\n","#timel\n","import warnings\n","from tqdm import tqdm_notebook as tqdm\n","import itertools\n","\n","\n","warnings.filterwarnings(\"ignore\")\n","SEED=42 # set random seed\n"],"metadata":{"id":"cDYN0yUZgfe8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Step : 2 Loading ypur data from disk for traning"],"metadata":{"id":"tYIv6B8TjgPe"}},{"cell_type":"code","source":["#mount google drive to collab notebook\n","from google.colab import drive\n","drive.mount(\"//content/drive\")"],"metadata":{"id":"0BV_ct4IiuV8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# changee working DIR\n","import os\n","os.chdir(\"/content/drive/MyDrive/Deep Learning project/Image classification\")"],"metadata":{"id":"0Im49baxknhl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Extract dataset.rar file\n","#!pip install patool\n","#import patoolib\n","#patoolib.extract_archive(\"dataset.rar\")\n","#patoolib.extract_archive(\"test_examples.rar\")"],"metadata":{"id":"tCw0dlRekhjI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize the data and labels\n","print(\"[INFO] loading images...\")\n","time1 = time.time()   # to measure time taken\n","data = []\n","labels = []\n","classes =[\"Forest\",\"Buildings\"]\n","\n","# Grab the image paths and randomly shuffle them\n","imagePaths = sorted(list(paths.list_images(\"dataset\")))   # data folder with 2 categorical folders\n","random.seed(SEED)\n","random.shuffle(imagePaths)\n","\n","# Progress bar\n","with tqdm (total = len(imagePaths)) as pbar:\n","  for imagePath in imagePaths:\n","    # Load the image, resize the image to be 32x32 pixels (ignoring aspect ratio),\n","    # flatten the\n","    image = cv2.imread(imagePath)\n","    image = cv2.resize(image, (32, 32)).flatten()\n","    data.append(image)\n","\n","    # Extract the class label from the image path\n","    label = imagePath.split(os.path.sep)[-2]\n","    label = 1 if label == \"Buildings\" else 0\n","    labels.append(label)\n","\n","    # update the progresbar\n","    pbar.update(1)\n","\n","# Scale the raw pixel intensities to the range [0,1]\n","data = np.array(data, dtype=\"float\") / 255.0\n","labels = np.array(labels)\n","\n","print(\"Time taken: {:.1f} seconds\".format(time.time() - time1))    # to measure time taken\n","print(\"done\")"],"metadata":{"id":"ZKk1K0XXlAiu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df=pd.DataFrame(data)\n","df['Label']=labels"],"metadata":{"id":"DAGO24VTm2Gt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"lt98kJQKvOF1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# samples data for first image\n","print('sample image:{}'.format(data[0]))\n","print('no of feature/pixels values:{}'.format(len(data[0]))) #32x32x3=3072\n","print('label:{}'.format(classes[labels[0]]))\n","\n"],"metadata":{"id":"16ZDBUjZvVWA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["128*128*3\n"],"metadata":{"id":"RFBVFMGBwPr6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#partition the data into 80% training and 20% valdiation\n","(trainX,testX,trainY,testY)=train_test_split(data,labels,test_size=0.2,random_state=SEED)"],"metadata":{"id":"j6g8X97DwnoW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainX.shape"],"metadata":{"id":"gw1w7qu6xvum"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainY.shape"],"metadata":{"id":"2cXSDt9KyYGB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["testX.shape"],"metadata":{"id":"Fpf2a8blyaf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["testY.shape"],"metadata":{"id":"vTiV2hHnydd-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainX"],"metadata":{"id":"clvdgPExyfD9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainY"],"metadata":{"id":"MbE_tRDjyhvO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","\n","lr = LogisticRegression()\n","lr.fit(trainX, trainY)\n","\n","pred = lr.predict(testX)\n","print(confusion_matrix(testY, pred))\n","print(classification_report(testY, pred))\n","print(accuracy_score(testY, pred))"],"metadata":{"id":"y7C9v5gfyw0K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3uVXoHST0VIV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# STEP 4 : Data preprocessing"],"metadata":{"id":"3bNogvz10WmP"}},{"cell_type":"code","source":["# convert the labels from integers/categories to vectors\n","trainY = to_categorical(trainY, num_classes=2)\n","testY = to_categorical(testY, num_classes=2)\n","\n","#[0,1] Buldings\n","#[1,0]Forest"],"metadata":{"id":"dErUIqjK0WYI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#testY"],"metadata":{"id":"yWD6YWcFywww"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainY"],"metadata":{"id":"qH3DZsMjywuA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_image=(trainX[25]*255).astype(\"int\")"],"metadata":{"id":"JIzYpqOfywq-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(sample_image.reshape(32,32,3))"],"metadata":{"id":"nSRNLCcPywoS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainY[25] #[0,1] means buildings [1,0] means forest"],"metadata":{"id":"39y0QKjeywli"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 5 : define the architecture for ANN model"],"metadata":{"id":"Ta6kmdVD1zvF"}},{"cell_type":"code","source":["# define the 3072-1024-512-1 architecture using Keras\n","model=Sequential()\n","#input layer 3072 as there are 32x32x3=3072 pixells in a flattened input image\n","#first hidden layer has 1024 nodes\n","model.add(Dense(units=1024,input_shape=(3072,),kernel_initializer=\"uniform\",activation='relu'))\n","\n","# # droppout for second layer\n","model .add(Dropout(0.4))\n","\n","# second hidden layer has 512 nodes\n","model.add(Dense(units=512,kernel_initializer=\"uniform\",activation='relu'))\n","\n","#output layer with number of possible class labels\n","model.add(Dense(units=2,kernel_initializer=\"uniform\",activation='softmax'))\n","\n"],"metadata":{"id":"7SrtQqW31yqk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# *Step* 6 : Compiling your tensflow ANN model"],"metadata":{"id":"y1F5W5m6Lx2J"}},{"cell_type":"code","source":["#initialize our inital learning rate and # of epoch to train for\n","INIT_LR=0.01\n","EPOCHS=50\n","#compile the model using SGD as our optimizer and categorical cross_entrophy loss\n","#(you'll want to use binary_crossentropy for class classifiction)\n","print('[INFO] compiling network network....')\n","opt = SGD(learning_rate=INIT_LR)\n","model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])"],"metadata":{"id":"YWbJfSh-ywig"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"BduqWuptywfg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 7 : Tranning Youe model"],"metadata":{"id":"GuNf9u-rNwwU"}},{"cell_type":"code","source":["# train the neural network on training data set\n","# batch_size (32) controls the size of each group of data to pass through the network\n","\n","H = model.fit(trainX,trainY,validation_data=(testX, testY),epochs=EPOCHS,batch_size=32)\n","\n","model.save(\"ANN_MODEL_{}.h5\".format(EPOCHS))"],"metadata":{"id":"H5CQaF8cywcv","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 8: Generate Plots for acc and val"],"metadata":{"id":"--vFH_7aRALI"}},{"cell_type":"code","source":["# plot the training and validation loss\n","N = np.arange(0, EPOCHS)\n","plt.style.use(\"ggplot\")\n","plt.figure(figsize = [10,8])\n","plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n","plt.title(\"ANN: Training & Validation Loss\")\n","plt.xlabel(\"Epoch #\", weight=\"bold\")\n","plt.ylabel(\"Loss\", weight=\"bold\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"x4pypYvwyrxK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot the training and validation accuracy\n","N = np.arange(0, EPOCHS)\n","plt.style.use(\"ggplot\")\n","plt.figure(figsize = [10,8])\n","plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n","plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n","plt.title(\"ANN: Training and Validation Accuracy\")\n","plt.xlabel(\"Epoch #\", weight=\"bold\")\n","plt.ylabel(\"Accuracy\", weight=\"bold\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"oES4wgB_RGre"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"V1ddI5WcUJ1b"}},{"cell_type":"code","source":["# Evaluate on test data\n","loss, accuracy = model.evaluate(testX, testY)\n","print(f\"Accuracy: {accuracy * 100:.2f}%\")"],"metadata":{"id":"axJuWYUNRGoF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","# Step 9 : Making Prediction Using your Tensorflow trained Model:"],"metadata":{"id":"G9jJyOSIZfDY"}},{"cell_type":"code","source":["def display_img(img):\n","  fig = plt.figure(figsize=(12,10))\n","  # plt.grid(b=None)\n","  ax = fig.add_subplot(111)\n","  ax.imshow(img)"],"metadata":{"id":"2t2wAIgoRGkh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load the input image an resize it to the target spatial dimansions:\n","import imutils\n","width = 32\n","height = 32\n","\n","# grab the image paths and randomly shuffle them\n","testimagePaths = sorted(list(paths.list_images(\"test_examples\")))\n","random.seed(SEED)\n","random.shuffle(testimagePaths)\n","\n","# Progress bar\n","with tqdm (total = len(testimagePaths)) as pbar:\n","  for imagePath in testimagePaths:\n","    # Load the image, resize the image to be\n","    image = cv2.imread(imagePath)\n","    output = image.copy()\n","    image = cv2.resize(image, (width, height))\n","    # scale the pixel intensities to the range [0,1]\n","    image = image.astype(\"float\") / 255.0\n","    image = image.flatten()\n","    image = image.reshape((1, image.shape[0]))\n","\n","    # make a prediction on the image\n","    preds = model.predict(image)\n","    i = preds.argmax(axis=1)[0]\n","    label = classes[i]\n","    label = \"{}: {:.2f}%\".format(label, preds[0][i] * 100)\n","    print(\"[INFO] {}\".format(label))\n","    output = imutils.resize(output, width=400)\n","    cv2.putText(output, label, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n","\n","    # Convert img to rgb format and display in notebook\n","    img = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n","    display_img(output)\n","    pbar.update(1)\n"],"metadata":{"collapsed":true,"id":"u91ek3nhRGgU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install gradio\n"],"metadata":{"id":"3iKj6-Nyi_9u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Deployment"],"metadata":{"id":"0AZV-jy4l9Ub"}},{"cell_type":"code","source":["import gradio as gr"],"metadata":{"id":"c-KbfT94i_59"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_image(image):\n","\n","  image = cv2.resize(image, (32,32))\n","\n","  #scale the pixel values to [0, 1]\n","  image = image.astype(\"float\") / 255.0\n","\n","  # for a simple fully-connected network, flatten the image\n","  image = image.flatten()\n","  image = image.reshape((1, image.shape[0]))\n","\n","  # make a predication on the image\n","  preds =model.predict(image).flatten()\n","  result = dict()\n","  result[\"Forest\"] = round(float(list(preds)[0]), 3)\n","  result[\"Buildings\"] = round(float(list(preds)[1]), 3)\n","  print(result)\n","\n","  return result\n","\n","im = gr.Image()\n","label = gr.Label(num_top_classes=2)\n","\n","gr.Interface(fn=predict_image, inputs=im, outputs=label, title=\"ANN Demo\").launch(share=True)"],"metadata":{"id":"FiDzHs8Pi_xL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mA7gdA0Bi_t9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"p1SWy01Zi_V8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Tu9v00mRRGb9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9CmdW6C1RGQB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ObieAKSLNvx8"},"execution_count":null,"outputs":[]}]}